for(t in 1:N){
test.id = all.test.id[, t]
cv.out = cv.glmnet(X[-test.id, ], Y[-test.id],
alpha = 0,lambda=seq(exp(-5),exp(1),length.out=100))
lamda[t,1:2] = range(log(cv.out$lambda))
lamda[t,3]=log(cv.out$lambda.min)
lamda[t,4]=log(cv.out$lambda.1se)
}
set.seed(1821)
lamda = matrix(0,nrow=50,ncol=4)
for(t in 1:N){
test.id = all.test.id[, t]
cv.out = cv.glmnet(X[-test.id, ], Y[-test.id],
alpha = 0,lambda=seq(exp(-4),exp(1),length.out=100))
lamda[t,1:2] = range(log(cv.out$lambda))
lamda[t,3]=log(cv.out$lambda.min)
lamda[t,4]=log(cv.out$lambda.1se)
}
R_1se = function(){
pse = c()
size = c()
total_time = 0
for(t in 1:N){
test.id = all.test.id[, t]
start.time = proc.time()
cv.out = cv.glmnet(X[-test.id, ], Y[-test.id],
alpha = 0,lambda=seq(exp(-4),exp(1),length.out=100))
best.lam = cv.out$lambda.1se
Ytest.pred = predict(cv.out, s = best.lam, newx = X[test.id, ])
time = proc.time() - start.time
total_time = total_time + time[1]
pse[t] = mean((Y[test.id] - Ytest.pred)^2)
# Exclude the computation for DF when recording computing time for Ridge,
ntrain = n - dim(all.test.id)[1]
tmpX = scale(X[-test.id, ]) * sqrt(ntrain / (ntrain - 1))
d = svd(tmpX)$d
# df for Ridge with lambda_1se
best.lam = cv.out$lambda.1se
size[t] = sum(d^2/(d^2 + best.lam*ntrain))
}
result = list(pse = pse,size = size,time = total_time)
return(result)
}
set.seed(1821)
R_1se_result =R_1se()
boxplot(R_1se_result$pse)
0+1*log(w2r1/w2r0)+1*log(w3r1/w3r0)
log(2)
log(10)
log2(2)
0+1*log2(w2r1/w2r0)+1*log2(w3r1/w3r0)
w2r1  = 41/100
w1r1 = 9/20
w2r1  = 41/100
w3r1 = 7/50
w1r0 = 0
w2r0 = 1/2
w3r0 = 1/2
0+1*log2(w2r1/w2r0)+1*log2(w3r1/w3r0)
0*log2(w1r1/w1r0)+1*log2(w2r1/w2r0)+1*log2(w3r1/w3r0)
0*log2(w1r1)+1*log2(w2r1/w2r0)+1*log2(w3r1/w3r0)
2*log2(w1r1)+2*log2(w2r1/w2r0)+1*log2(w3r1/w3r0)
3*log2(w1r1)+2*log2(w2r1/w2r0)+0*log2(w3r1/w3r0)
w1r1 = 5/12
w2r1  = 5/12
w3r1 = 1/6
w1r0 = 1/2
w2r0 = 1/2
w3r0 = 0
0*log2(w1r1)+1*log2(w2r1/w2r0)+1*log2(w3r1/w3r0)
2*log2(w1r1)+2*log2(w2r1/w2r0)+1*log2(w3r1/w3r0)
3*log2(w1r1)+2*log2(w2r1/w2r0)+0*log2(w3r1/w3r0)
w1r1 = 59/120
w2r1  = 59/120
w3r1 = 1/60
w1r0 = 5/12
w2r0 = 5/12
w3r0 = 1/6
0*log2(w1r1/w1r0)+1*log2(w2r1/w2r0)+1*log2(w3r1/w3r0)
2*log2(w1r1/w1r0)+2*log2(w2r1/w2r0)+1*log2(w3r1/w3r0)
3*log2(w1r1/w1r0)+2*log2(w2r1/w2r0)+0*log2(w3r1/w3r0)
data(Boston)
library(MASS)
data(Boston)
dim(dis)
dim(nox)
dim(Boston$nox)
Boston$nox = poly(Boston$dis,3)
fit = lm(nox ~ poly(dis,3), data = Boston)
round(summary(fit)$coef, dig = 3)
library(MASS)
data(Boston)
fit = lm(nox ~ poly(dis,3), data = Boston)
round(summary(fit)$coef, dig = 3)
fit
rrs(fit)
rss(fit)
RSS(fit)
summary(fit)
round(summary(fit)$coef, dig = 2)
predict(fit, newdata = list(nox=6))
fit = lm(nox ~ poly(dis,3), data = Boston)
predict(fit, newdata = list(nox=6))
predict(fit, newdata = list(dis=6))
round(summary(fit)$coef, dig = 2)
fit2 = lm(nox ~ poly(dis,4), data = Boston)
fit2 = lm(nox ~ poly(dis,4), data = Boston)
predict(fit2, newdata = list(dis=6))
summary(fit2)
fit$residuals
deviance(fit)
deviance(fit2)
myfit1 = lm(nox ~ bs(dis, df=3), data=Boston)
help(bs)
require(splines)
help(bs)
myfit1 = lm(nox ~ bs(dis, df=3), data=Boston)
lm(nox ~ bs(dis, knots=median(dis)), data=Boston)
lm(nox ~ bs(dis, df=3), data=Boston)
lm(nox ~ poly(dis, 3), data=Boston)
lm(nox ~ bs(dis, df= 5, intercept=TRUE), data=Boston)
lm(nox ~ bs(dis, df= 4, intercept=TRUE), data=Boston)
lm(nox ~ bs(dis, knots=quantile(dis, prob=c(0.25, 0.5, 0.75)), data=Boston)
lm(nox ~ bs(dis, knots=quantile(dis, prob=c(0.25, 0.5, 0.75)), data=Boston))
lm(nox ~ bs(dis, knots=quantile(dis, prob=c(0.25, 0.5, 0.75)), data=Boston))
data(Boston)
lm(nox ~ bs(dis, knots=quantile(dis, prob=c(0.25, 0.5, 0.75)), data=Boston))
lm(nox ~ bs(dis, df=3), data=Boston)
lm(nox ~ bs(dis, knots=median(dis)), data=Boston)
summary(a)
a = lm(nox ~ bs(dis, df=3), data=Boston)
summary(a)
summary(b)
b = lm(nox ~ bs(dis, knots=median(dis)), data=Boston)
summary(b)
c = lm(nox ~ bs(dis, df= 5, intercept=TRUE), data=Boston)
summary(c)
c = lm(nox ~ poly(dis, 3), data=Boston)
summary(c)
summary(a)
c = lm(nox ~ bs(dis, df= 5, intercept=TRUE), data=Boston)
summary(c)
d = lm(nox ~ bs(dis, df= 4, intercept=TRUE), data=Boston)
summary(d)
e = lm(nox ~ bs(dis, knots=quantile(dis, prob=c(0.25, 0.5, 0.75)), data=Boston))
e = lm(nox ~ bs(dis, knots=quantile(dis, prob=c(0.25, 0.5, 0.75)), data=Boston))
e = lm(nox ~ bs(dis, knots=quantile(dis, probs=c(0.25, 0.5, 0.75)), data=Boston))
e = lm(nox ~ bs(dis, knots=quantile(dis, probs=seq(0.25, 0.5, 0.75)), data=Boston))
e = lm(nox ~ bs(dis, knots=quantile(dis, probs=seq(0.25, 0.5, 0.75)), data=Boston))
library(MASS)
require(splines)
help(bs)
data(Boston)
e = lm(nox ~ bs(dis, knots=quantile(dis, probs=seq(0.25, 0.5, 0.75)), data=Boston))
e = lm(nox ~ bs(dis, knots=quantile(dis, prob=c(0.25, 0.5, 0.75)), data=Boston)
)
myfit2 = lm(nox ~ bs(dis, df=4), data=Boston)
myfit2 = lm(nox ~ bs(dis, df=4), data=Boston)
a = lm(nox ~ bs(dis, knots=median(dis)), data=Boston)
c = lm(nox ~ poly(dis, 3), data=Boston)
d = lm(nox ~ bs(dis, df= 4, intercept=TRUE), data=Boston)
e = lm(nox ~ bs(dis, df= 5, intercept=TRUE), data=Boston)
summary(myfit2)
summary(a)
summary(c)
summary(d)
summary(e)
myfit = lm(nox ~ bs(dis, df=3), data=Boston)
summary(myfit)
n = 6
X = matrix(c(1, 4, 1, 3, 0, 4, 5, 1, 6, 2, 4, 0),
nrow = n, byrow = T)
plot(X)
data("caffeine")
Y = as.matrix(caffeine[,-1])
library(msos)
data("caffeine")
Y = as.matrix(caffeine[,-1])
View(Y)
View(Y)
x = cbind(1,c(rep(-1,9),rep(0,10),rep(1,9)),c(rep(1,9),rep(-9/5,10),rep(1,9)))
View(Y)
View(x)
z = matrix(c(1,-1,1,1),nrow = 2,byrow = T)
View(z)
z = cbind(1,c(-1,1))
for(p in (1:3)) for(l in (1:2)) {
pattern = matrix(0,ncol = 2, nrow = 3)
pattern[1:p,1:l] = 1
}
pattern
pattern = matrix(0,nrow=5,ncol=3)
if(i>0) pattern[1,1:i] = 1
if(j>0) pattern[2,1:j] = 1
if(k>0) pattern[3,1:k] = 1
if(l>0) pattern[4,1:l] = 1
if(m>0) pattern[5,1:m] = 1
View(pattern)
xyb = cbind(x,y)
y = as.matrix(caffeine[,-1])
library(msos)
data("caffeine")
y = as.matrix(caffeine[,-1])
x = cbind(1,c(rep(-1,9),rep(0,10),rep(1,9)),c(rep(1,9),rep(-9/5,10),rep(1,9)))
z = matrix(c(1,-1,1,1),nrow = 2,byrow = T)
xyb = cbind(x,y)
View(xyb)
for(p in (1:3)) for(l in (1:2)) {
pattern = matrix(0,ncol = 2, nrow = 3)
pattern[1:p,1:l] = 1
bothsidesmodel = bothsidesmodel.mle(x,y,z,pattern)
results = rbind(results,c(bothsidesmodel$Dev,bothsidesmodel$Dim,
bothsidesmodel$AICc,bothsidesmodel$BIC))
b0 = c(p,l,bsm$ResidSS,bsm$Dim,bsm$Cp)
models = rbind(models,b0)
}
results = NULL
models = NULL
for(p in (1:3)) for(l in (1:2)) {
pattern = matrix(0,ncol = 2, nrow = 3)
pattern[1:p,1:l] = 1
bothsidesmodel = bothsidesmodel.mle(x,y,z,pattern)
results = rbind(results,c(bothsidesmodel$Dev,bothsidesmodel$Dim,
bothsidesmodel$AICc,bothsidesmodel$BIC))
b0 = c(p,l,bsm$ResidSS,bsm$Dim,bsm$Cp)
models = rbind(models,b0)
}
results = NULL
models = NULL
for(p in (1:3)) for(l in (1:2)) {
pattern = matrix(0,ncol = 2, nrow = 3)
pattern[1:p,1:l] = 1
bothsidesmodel = bothsidesmodel.mle(x,y,z,pattern)
results = rbind(p,l,c(bothsidesmodel$Dev,bothsidesmodel$Dim,
bothsidesmodel$AICc,bothsidesmodel$BIC))
models = rbind(models,results)
}
models
results = NULL
models = NULL
for(p in (1:3)) for(l in (1:2)) {
pattern = matrix(0,ncol = 2, nrow = 3)
pattern[1:p,1:l] = 1
bothsidesmodel = bothsidesmodel.mle(x,y,z,pattern)
results = rbind(p,l,bothsidesmodel$Dev,bothsidesmodel$Dim,
bothsidesmodel$AICc,bothsidesmodel$BIC)
models = rbind(models,results)
}
models
results = NULL
models = NULL
for(p in (1:3)) for(l in (1:2)) {
pattern = matrix(0,ncol = 2, nrow = 3)
pattern[1:p,1:l] = 1
bothsidesmodel = bothsidesmodel.mle(x,y,z,pattern)
results = c(p,l,bothsidesmodel$Dev,bothsidesmodel$Dim,
bothsidesmodel$AICc,bothsidesmodel$BIC)
models = rbind(models,results)
}
models
results = NULL
models = NULL
for(p in (1:3)) for(l in (1:2)) {
pattern = matrix(0,ncol = 2, nrow = 3)
pattern[1:p,1:l] = 1
bothsidesmodel = bothsidesmodel.mle(x,y,z,pattern)
results = c(p,l,bothsidesmodel$Dev,bothsidesmodel$Dim,,bothsidesmodel$BIC)
models = rbind(models,results)
}
results = NULL
models = NULL
for(p in (1:3)) for(l in (1:2)) {
pattern = matrix(0,ncol = 2, nrow = 3)
pattern[1:p,1:l] = 1
bothsidesmodel = bothsidesmodel.mle(x,y,z,pattern)
results = c(p,l,bothsidesmodel$Dev,bothsidesmodel$Dim,bothsidesmodel$BIC)
models = rbind(models,results)
}
results
for (x in 6){
print(1)
}
for (x in 1:6){
print(1)
}
models[,4]
models
bic = models[,5]
p = exp(-(bic-max(bic))/2)
p = 100*p/sum(p)
final = rbind(models,p)
View(models)
final = c(models,p)
colnames(finals) = c("p*","l*","ResidSS","d","Cp","1")
colnames(final) = c("p*","l*","ResidSS","d","Cp","1")
View(models)
final = cbind(models,p)
colnames(final) = c("p*","l*","ResidSS","d","Cp","1")
final
colnames(final) = c("p*","l*","Deviance","Dimension"," BIC ","P")
final
colnames(final) = c("p*","l*","Deviance","Dimension"," BIC ","probability")
final
View(pattern)
for(p in (1:3)) for(l in (1:2)) {
pattern = matrix(0,ncol = 2, nrow = 3)
pattern[1:p,1:l] = 1
bothsidesmodel = bothsidesmodel.mle(x,y,z,pattern)
results = c(p,l,bothsidesmodel$Dev,bothsidesmodel$Dim,bothsidesmodel$BIC,
bothsidesmodel$Beta)
models = rbind(models,results)
}
bothsidesmodel$Beta
best_pattern = cbind(c(1,1,0),c(1,1,0))
View(best_pattern)
best_bothsidesmodel = bothsidesmodel.mle(x,y,z,best_pattern)
best_bothsidesmodel$beta
best_bothsidesmodel = bothsidesmodel.mle(x,y,z,best_pattern)
y = as.matrix(caffeine[,-1])
x = cbind(1,c(rep(-1,9),rep(0,10),rep(1,9)),c(rep(1,9),rep(-9/5,10),rep(1,9)))
z = matrix(c(1,-1,1,1),nrow = 2,byrow = T)
best_bothsidesmodel = bothsidesmodel.mle(x,y,z,best_pattern)
best_bothsidesmodel$beta
best_bothsidesmodel$Beta
y = as.matrix(caffeine[,-1])
x = cbind(1,c(rep(-1,9),rep(0,10),rep(1,9)),c(rep(1,9),rep(-9/5,10),rep(1,9)))
z = matrix(c(1,-1,1,1),nrow = 2,byrow = T)
results = NULL
models = NULL
for(p in (1:3)) for(l in (1:2)) {
pattern = matrix(0,ncol = 2, nrow = 3)
pattern[1:p,1:l] = 1
bothsidesmodel = bothsidesmodel.mle(x,y,z,pattern)
bothsidesmodel$Beta
results = c(p,l,bothsidesmodel$Dev,bothsidesmodel$Dim,bothsidesmodel$BIC)
models = rbind(models,results)
}
y = as.matrix(caffeine[,-1])
x = cbind(1,c(rep(-1,9),rep(0,10),rep(1,9)),c(rep(1,9),rep(-9/5,10),rep(1,9)))
z = matrix(c(1,-1,1,1),nrow = 2,byrow = T)
results = NULL
models = NULL
for(p in (1:3)) for(l in (1:2)) {
pattern = matrix(0,ncol = 2, nrow = 3)
pattern[1:p,1:l] = 1
bothsidesmodel = bothsidesmodel.mle(x,y,z,pattern)
print(bothsidesmodel$Beta)
results = c(p,l,bothsidesmodel$Dev,bothsidesmodel$Dim,bothsidesmodel$BIC)
models = rbind(models,results)
}
library(msos)
data("caffeine")
y = as.matrix(caffeine[,-1])
x = cbind(1,c(rep(-1,9),rep(0,10),rep(1,9)),c(rep(1,9),rep(-9/5,10),rep(1,9)))
z = matrix(c(1,-1,1,1),nrow = 2,byrow = T)
results = NULL
models = NULL
for(p in (1:3)) for(l in (1:2)) {
pattern = matrix(0,ncol = 2, nrow = 3)
pattern[1:p,1:l] = 1
bothsidesmodel = bothsidesmodel.mle(x,y,z,pattern)
results = c(p,l,bothsidesmodel$Dev,bothsidesmodel$Dim,bothsidesmodel$BIC)
models = rbind(models,results)
}
bic = models[,5]
p = exp(-(bic-max(bic))/2)
p = 100*p/sum(p)
final = cbind(models,p)
colnames(final) = c("p*","l*","Deviance","Dimension"," BIC ","probability")
final
best_pattern = cbind(c(1,1,0),c(1,1,0))
best_bothsidesmodel = bothsidesmodel.mle(x,y,z,best_pattern)
best_bothsidesmodel$Beta
knitr::opts_chunk$set(echo = FALSE)
library(HMM)
myBW = function(x, A, B, w, n.iter = 100){
# Input:
# x: T-by-1 observation sequence
# A: initial estimate for mz-by-mz transition matrix
# B: initial estimate for mz-by-mx emission matrix
# w: initial estimate for mz-by-1 initial distribution over Z_1
# Output MLE of A and B; we do not update w
# list(A = A, B=B, w = w)
for(i in 1:n.iter){
update.para = BW.onestep(x, A, B, w)
A = update.para$A
B = update.para$B
}
return(list(A = A, B = B, w = w))
}
BW.onestep = function(x, A, B, w){
# Input:
# x: T-by-1 observation sequence
# A: current estimate for mz-by-mz transition matrix
# B: current estimate for mz-by-mx emission matrix
# w: current estimate for mz-by-1 initial distribution over Z_1
# Output the updated parameters
# para = list(A = A1, B = B1)
# We DO NOT update the initial distribution w
T = length(x)
mz = nrow(A)
alp = forward.prob(x, A, B, w)
beta = backward.prob(x, A, B, w)
myGamma = array(0, dim=c(mz, mz, T-1))
###
## YOUR CODE:
## Compute gamma_t(i,j), which are stored in myGamma
##
for (i in 1:mz){
for (j in 1:mz){
for (t in 1:T-1){
myGamma[i,j,t] = alp[t,i]*A[i,j]*B[j,x[t+1]]*beta[t+1,j]
}
}
}
A = rowSums(myGamma, dims = 2)
A = A/rowSums(A)
tmp = apply(myGamma, c(1, 3), sum)  # mz-by-(T-1)
tmp = cbind(tmp, colSums(myGamma[, , T-1]))
for(l in 1:mx){
B[, l] = rowSums(tmp[, which(x==l)])
}
B = B/rowSums(B)
return(list(A = A, B = B))
}
forward.prob = function(x, A, B, w){
# Output the forward probability matrix alp
# alp: T by mz, (t, i) entry = P(x_{1:t}, Z_t = i)
T = length(x)
mz = nrow(A)
alp = matrix(0, T, mz)
# fill in the first row of alp
alp[1, ] = w*B[, x[1]]
# Recursively compute the remaining rows of alp
for(t in 2:T){
tmp = alp[t-1, ] %*% A
alp[t, ] = tmp * B[, x[t]]
}
return(alp)
}
backward.prob = function(x, A, B, w){
# Output the backward probability matrix beta
# beta: T by mz, (t, i) entry = P(x_{(t+1):n} | Z_t = i)
# for t=1, ..., n-1
T = length(x)
mz = nrow(A)
beta = matrix(1, T, mz)
# The last row of beta is all 1.
# Recursively compute the previous rows of beta
for(t in (T-1):1){
tmp = as.matrix(beta[t+1, ] * B[, x[t+1]])  # make tmp a column vector
beta[t, ] = t(A %*% tmp)
}
return(beta)
}
myViterbi = function(X, A, B, w){
p = c(log(w[1]*B[1,X[1]]),log(w[2]*B[2,X[1]]))
Z1 = c(1)
Z2 = c(2)
for (i in 2:length(X)){
p1 = c(p[1]+log(A[Z1[i-1],1]*B[1,X[i]]),p[2]+log(A[Z2[i-1],1]*B[1,X[i]]))
p2 = c(p[1]+log(A[Z1[i-1],2]*B[2,X[i]]),p[2]+log(A[Z2[i-1],2]*B[2,X[i]]))
if(p1[1]>p1[2]) new_Z1=c(Z1,1) else new_Z1=c(Z2,1)
if(p2[1]>p2[2]) new_Z2=c(Z1,2) else new_Z2=c(Z2,2)
Z1 = new_Z1
Z2 = new_Z2
p=c(max(p1),max(p2))
}
if (p[1]>p[2]) best_Z = Z1 else  best_Z = Z2
return (ifelse(best_Z==1, "A", "B"))
}
data = read.csv("Coding3_HMM_Data.csv")
mz=2; mx=3
ini.A = matrix(1, mz, mz)
ini.A = ini.A/rowSums(ini.A)
ini.B = matrix(1:6, mz, mx)
ini.B = ini.B/rowSums(ini.B)
ini.w = c(1/2, 1/2)
myout = myBW(data$X, ini.A, ini.B, ini.w, n.iter = 100)
myout.Z = myViterbi(data$X, myout$A, myout$B, ini.w)
write.table(myout.Z, file = "Coding3_HMM_Viterbi_Output.txt",
row.names = FALSE, col.names = FALSE)
true.viterbi = viterbi(true.out$hmm, data$X)
#write.table(true.viterbi, file = "Coding3_HMM_True_Viterbi_Output.txt",
#            row.names = FALSE, col.names = FALSE)
sum(true.viterbi != myout.Z)
hmm0 =initHMM(c("A", "B"), c(1, 2, 3),
startProbs = ini.w,
transProbs = ini.A, emissionProbs = ini.B)
true.out = baumWelch(hmm0, data$X, maxIterations=100, pseudoCount=0)
true.out$hmm
true.viterbi = viterbi(true.out$hmm, data$X)
#write.table(true.viterbi, file = "Coding3_HMM_True_Viterbi_Output.txt",
#            row.names = FALSE, col.names = FALSE)
sum(true.viterbi != myout.Z)
setwd("~/Desktop/fa18/stat542/stat542_pj3")
raw_data = read.csv('loan_stat542.csv')
raw_data = read.csv('loan_stat542.csv')
testID = read.table(file="Project3_test_id.csv", sep="")
testID[,1]
testID = read.csv("Project3_test_id.csv")
testID[,1]
View(raw_data)
View(raw_data)
train = raw_data[!raw_data$id %in% testID[,1], ]
write.csv(train,'train.csv',row.names=FALSE)
test = raw_data[raw_data$PID %in% testID[,1], ]
test = raw_data[raw_data$id %in% testID[,1], ]
test = subset( test, select = -loan_status)
write.csv(test,'test.csv',row.names=FALSE )
test
View(test)
