# n.comp - the number of components to keep in the singular value
#         decomposition
#
# returns:
#  the rank-reduced approximation of the training data
train[is.na(train)] <- 0
z <- svd(train[, 2:ncol(train)], nu=n.comp, nv=n.comp)
s <- diag(z$d[1:n.comp])
train[, 2:ncol(train)] <- z$u %*% s %*% t(z$v)
train
}
##### Prediction Loop #####
mypredict <- function() {
###### Create train and test time-series #######
if (t > 1) {
# append the previous periods test data to the current training data
train <<- rbind(train, new_test)
}
# filter test data.frame for the month that needs predictions
# backtesting starts during March 2011
start_date <- ymd("2011-03-01") %m+% months(2 * (t - 1))
end_date <- ymd("2011-05-01") %m+% months(2 * (t - 1))
test_month <- test %>%
filter(Date >= start_date & Date < end_date)
# Dates are not the same across months!
test_dates <- unique(test_month$Date)
num_test_dates <- length(test_dates)
# Not all stores may need predictions either
all_stores <- unique(test_month$Store)
num_stores <- length(all_stores)
# Most importantly not all departments need predictions
test_depts <- unique(test_month$Dept)
# Dateframe with (num_test_dates x num_stores) rows
test_frame <- data.frame(
Date=rep(test_dates, num_stores),
Store=rep(all_stores, each=num_test_dates)
)
# Create the same dataframe for the training data
# (num_train_dates x num_stores)
train_dates <- unique(train$Date)
num_train_dates <- length(train_dates)
train_frame <- data.frame(
Date=rep(train_dates, num_stores),
Store=rep(all_stores, each=num_train_dates)
)
#### Perform a individual forecasts for each department
for (dept in test_depts) {
# filter for the particular department in the training data
train_dept_ts <- train %>%
filter(Dept == dept) %>%
select(Store, Date, Weekly_Sales)
# Reformat so that each column is a weekly time-series for that
# store's department.
# The dataframe has a shape (num_train_dates, num_stores)
train_dept_ts <- train_frame %>%
left_join(train_dept_ts, by = c('Date', 'Store')) %>%
spread(Store, Weekly_Sales)
# We create a similar dataframe to hold the forecasts on
# the dates in the testing window
test_dept_ts <- test_frame %>%
mutate(Weekly_Sales = 0) %>%
spread(Store, Weekly_Sales)
###### Model Fitting / Forecasting ######
# naive forecast
f_naive <- naive_model(train_dept_ts, test_dept_ts)
test_month <- update_forecast(test_month, f_naive, dept, 1)
f_naive1 <- stlf.svd(train_dept_ts, test_dept_ts, model.type='ets', n.comp=12)
test_month <- update_forecast(test_month, f_naive1, dept, 2)
#f_naive2 <- stlf.nn(train_dept_ts, test_dept_ts,k=5, level1=0.95, level2=0.8)
#test_month <- update_forecast(test_month, f_naive2, dept, 3)
}
# update global test dataframe
update_test(test_month)
}
library(tidyverse)
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
# time-series CV
for (t in 1:num_folds) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
################ Load Environment ##################
# clean workspace
rm(list = ls())
# load necessary packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
"lubridate",
"forecast",
"tidyverse"
)
# converts a Date x num_store forecast to a dataframe
# with Date, Store, value = Weekly_Price columns
flatten_forecast <- function(f_model) {
f_model %>%
gather(Store, value, -Date, convert = TRUE)
}
# Adds forecasts to the testing dataframe
update_forecast <- function(test_month, dept_preds, dept, num_model) {
dept_preds <- flatten_forecast(dept_preds)
pred.d <- test_month %>%
filter(Dept == dept) %>%
select('Store', 'Date') %>%
left_join(dept_preds, by = c('Store', 'Date'))
pred.d.idx <- test_month$Dept == dept
pred.d <- test_month[pred.d.idx, c('Store', 'Date')] %>%
left_join(dept_preds, by = c('Store', 'Date'))
if (num_model == 1) {
test_month$Weekly_Pred1[pred.d.idx] <- pred.d$value
} else if(num_model == 2) {
test_month$Weekly_Pred2[pred.d.idx] <- pred.d$value
} else {
test_month$Weekly_Pred3[pred.d.idx] <- pred.d$value
}
test_month
}
# update forecasts in the global test dataframe
update_test <- function(test_month) {
test <<- test %>%
dplyr::left_join(test_month,
by = c('Date', 'Store', 'Dept', 'IsHoliday')) %>%
mutate(Weekly_Pred1 = coalesce(Weekly_Pred1.y, Weekly_Pred1.x)) %>%
mutate(Weekly_Pred2 = coalesce(Weekly_Pred2.y, Weekly_Pred2.x)) %>%
mutate(Weekly_Pred3 = coalesce(Weekly_Pred3.y, Weekly_Pred3.x)) %>%
select(-Weekly_Pred1.x, -Weekly_Pred1.y,
-Weekly_Pred2.x, -Weekly_Pred2.y,
-Weekly_Pred3.x, -Weekly_Pred3.y)
}
##### Model Building Functions #####
# Forecasts out the last observation in the training data
naive_model<- function(train_ts, test_ts){
num_forecasts <- nrow(test_ts)
train_ts[is.na(train_ts)] <- 0
# naive forecast per store
for(j in 2:ncol(train_ts)){
store_ts <- ts(train_ts[, j], frequency=52)
test_ts[, j] <- naive(store_ts, num_forecasts)$mean
}
test_ts
}
#tslm
tslm.basic <- function(train, test){
# Computes a forecast using linear regression and seasonal dummy variables
#
# args:
# train - A matrix of Weekly_Sales values from the training set of dimension
#         (number of weeeks in training data) x (number of stores)
# test - An all-zeros matrix of dimension:
#       (number of weeeks in training data) x (number of stores)
#       The forecasts are written in place of the zeros.
#
# returns:
#  the test(forecast) data frame with the forecasts filled in
horizon <- nrow(test)
train[is.na(train)] <- 0
for(j in 2:ncol(train)){
s <- ts(train[, j], frequency=52)
model <- tslm(s ~ trend + season)
fc <- forecast(model, h=horizon)
test[, j] <- as.numeric(fc$mean)
}
test
}
#stlf
stlf.svd <- function(train, test, model.type, n.comp){
# Replaces the training data with a rank-reduced approximation of itself,
# then forecasts each store using stlf() from the forecast package.
# That function performs an STL decomposition on each series, seasonally
# adjusts the data, non-seasonally forecasts the seasonally adjusted data,
# and then adds in the naively extended seasonal component to get the
# final forecast.
#
# args:
# train - A matrix of Weekly_Sales values from the training set of dimension
#         (number of weeeks in training data) x (number of stores)
# test - An all-zeros matrix of dimension:
#       (number of weeeks in training data) x (number of stores)
#       The forecasts are written in place of the zeros.
# model.type - one of 'ets' or 'arima', specifies which type of model to
#        use for the non-seasonal forecast
# n.comp - the number of components to keep in the singular value
#         decomposition that is performed for preprocessing
#
# returns:
#  the test(forecast) data frame with the forecasts filled in
horizon <- nrow(test)
train <- preprocess.svd(train, n.comp)
for(j in 2:ncol(train)){
s <- ts(train[, j], frequency=52)
if(model.type == 'ets'){
fc <- stlf(s,
h=horizon,
s.window=3,
method='ets',
ic='bic',
opt.crit='mae')
}else if(model.type == 'arima'){
fc <- stlf(s,
h=horizon,
s.window=3,
method='arima',
ic='bic')
}else{
stop('Model type must be one of ets or arima.')
}
pred <- as.numeric(fc$mean)
test[, j] <- pred
}
test
}
preprocess.svd <- function(train, n.comp){
# Replaces the training data with a rank-reduced approximation of itself.
# This is for noise reduction. The intuition is that characteristics
# that are common across stores (within the same department) are probably
# signal, while those that are unique to one store may be noise.
#
# args:
# train - A matrix of Weekly_Sales values from the training set of dimension
#         (number of weeeks in training data) x (number of stores)
# n.comp - the number of components to keep in the singular value
#         decomposition
#
# returns:
#  the rank-reduced approximation of the training data
train[is.na(train)] <- 0
z <- svd(train[, 2:ncol(train)], nu=n.comp, nv=n.comp)
s <- diag(z$d[1:n.comp])
train[, 2:ncol(train)] <- z$u %*% s %*% t(z$v)
train
}
##### Prediction Loop #####
mypredict <- function() {
###### Create train and test time-series #######
if (t > 1) {
# append the previous periods test data to the current training data
train <<- rbind(train, new_test)
}
# filter test data.frame for the month that needs predictions
# backtesting starts during March 2011
start_date <- ymd("2011-03-01") %m+% months(2 * (t - 1))
end_date <- ymd("2011-05-01") %m+% months(2 * (t - 1))
test_month <- test %>%
filter(Date >= start_date & Date < end_date)
# Dates are not the same across months!
test_dates <- unique(test_month$Date)
num_test_dates <- length(test_dates)
# Not all stores may need predictions either
all_stores <- unique(test_month$Store)
num_stores <- length(all_stores)
# Most importantly not all departments need predictions
test_depts <- unique(test_month$Dept)
# Dateframe with (num_test_dates x num_stores) rows
test_frame <- data.frame(
Date=rep(test_dates, num_stores),
Store=rep(all_stores, each=num_test_dates)
)
# Create the same dataframe for the training data
# (num_train_dates x num_stores)
train_dates <- unique(train$Date)
num_train_dates <- length(train_dates)
train_frame <- data.frame(
Date=rep(train_dates, num_stores),
Store=rep(all_stores, each=num_train_dates)
)
#### Perform a individual forecasts for each department
for (dept in test_depts) {
# filter for the particular department in the training data
train_dept_ts <- train %>%
filter(Dept == dept) %>%
select(Store, Date, Weekly_Sales)
# Reformat so that each column is a weekly time-series for that
# store's department.
# The dataframe has a shape (num_train_dates, num_stores)
train_dept_ts <- train_frame %>%
left_join(train_dept_ts, by = c('Date', 'Store')) %>%
spread(Store, Weekly_Sales)
# We create a similar dataframe to hold the forecasts on
# the dates in the testing window
test_dept_ts <- test_frame %>%
mutate(Weekly_Sales = 0) %>%
spread(Store, Weekly_Sales)
###### Model Fitting / Forecasting ######
# naive forecast
f_naive <- naive_model(train_dept_ts, test_dept_ts)
test_month <- update_forecast(test_month, f_naive, dept, 1)
f_tslm <- tslm.basic(train_dept_ts, test_dept_ts)
test_month <- update_forecast(test_month, f_tslm, dept, 2)
test_month <- update_forecast(test_month, f_tslm, dept, 3)
if (start_date > ymd("2011-02-01")){
f_tslm_stlf <- stlf.svd(train_dept_ts, test_dept_ts, model.type='arima', n.comp=12)
test_month <- update_forecast(test_month, f_tslm_stlf, dept, 3)
}
}
# update global test dataframe
update_test(test_month)
}
library(tidyverse)
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
# time-series CV
for (t in 1:num_folds) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
mean(wae$model_three)
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
install.packages("reshape")
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
postprocess <- function(train, test, ...){
# Iterates over the departments and calls shift() on each.
#
# args:
#  train - the training set as returned from raw.train() in util
#  test - a reloaded submission or a data frame similar to test,
#         from raw.test() in util, but with predictions in the
#         Weekly_Sales field
# ... - additional arguments passed to shift()
#
# returns:
#  the data frame input as test, after calling shift on it department-wise
if('Id' %in% names(test)){
#This is a saved submission
sales <- test$Weekly_Sales
test <- raw.test()
test$Weekly_Sales <- sales
}
test.dates <- unique(test$Date)
num.test.dates <- length(test.dates)
all.stores <- unique(test$Store)
num.stores <- length(all.stores)
test.depts <- unique(test$Dept)
forecast.frame <- data.frame(Date=rep(test.dates, num.stores),
Store=rep(all.stores, each=num.test.dates))
pred <- test
pred$Weekly_Sales <- 0
train.dates <- unique(train$Date)
num.train.dates <- length(train.dates)
train.frame <- data.frame(Date=rep(train.dates, num.stores),
Store=rep(all.stores, each=num.train.dates))
for(d in test.depts){
print(paste('dept:', d))
tr.d <- join(train.frame,
train[train$Dept==d, c('Store','Date','Weekly_Sales')])
tr.d <- cast(tr.d, Date ~ Store)
fc.d <- join(forecast.frame,
test[test$Dept==d, c('Store', 'Date', 'Weekly_Sales')])
fc.d <- cast(fc.d, Date ~ Store)
result <- shift(tr.d, fc.d, ...)
result <- melt(result)
pred.d.idx <- pred$Dept==d
pred.d <- pred[pred.d.idx, c('Store', 'Date')]
pred.d <- join(pred.d, result)
pred$Weekly_Sales[pred.d.idx] <- pred.d$value
}
pred
}
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
View(preds)
pred
View(scoring_tbl)
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wqe
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wqe
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain1.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
mean(wae$model_three)
source('~/Desktop/fa18/stat542/stat542_pj2/mymain.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
source('~/Desktop/fa18/stat542/stat542_pj2/mymain.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
source('~/Desktop/fa18/stat542/stat542_pj2/mymain.R')
source('~/Desktop/fa18/stat542/stat542_pj2/evaluationCode.R')
wae
mean(wae$model_one)
mean(wae$model_two)
mean(wae$model_three)
