mycoef = predict(l1, x= X, y= Y,
s=0.004, type="coefficients", exact=TRUE,
thresh = 1e-08)
glm.probs=predict(l1,Caravan[test,], type="response")
glm.probs=predict(l1,Caravan[test,])
myc = predict(l1, x= X, y= Y,
s=0.004, type="response", exact=TRUE,
thresh = 1e-08)
glm.probs=predict(l1,data.matrix(Caravan[test,]), type="response")
data.matrix(Caravan[test,])
l1=glmnet(X,Y,family="binomial",alpha=1,lambda = 0.004)
glm.probs=predict(l1,data.matrix(Caravan[test,]), type="response")
myc = predict(l1, x= X, y= Y, newx=Caravan[test,]
s=0.004, type="response", exact=TRUE,
thresh = 1e-08)
myc = predict(l1, x= X, y= Y, newx=Caravan[test,],
s=0.004, type="response", exact=TRUE,
thresh = 1e-08)
myc = predict(l1, x= X, y= Y, newx=data.matrix(Caravan[test,]),
s=0.004, type="response", exact=TRUE,
thresh = 1e-08)
data(aSAH)
aSAH$outcome
knitr::opts_chunk$set(echo = FALSE)
set.seed(1821);
set.seed(1821);
library(dplyr)
library(recommenderlab)
install.packages("recommenderlab")
set.seed(1821);
library(dplyr)
library(recommenderlab)
library(reshape2)
set.seed(1821);
library(dplyr)
library(recommenderlab)
library(reshape2)
# ratings data
# use colClasses = 'NULL' to skip columns
ratings = read.csv('ratings.dat', sep = ':',
colClasses = c('integer', 'NULL'), header = FALSE)
colnames(ratings) = c('UserID', 'MovieID', 'Rating', 'Timestamp')
dim(ratings) # 1000209-by-4
ratings[1:4, ]
# movies data
# In movies.dat, some movie names contain single colon (:), so the above
# method does not work.
movies = readLines('movies.dat')
movies = strsplit(movies, split = "::", fixed = TRUE, useBytes = TRUE)
movies = matrix(unlist(movies), ncol = 3, byrow = TRUE)
movies = data.frame(movies, stringsAsFactors = FALSE)
colnames(movies) = c('MovieID', 'Title', 'Genres')
movies$MovieID = as.integer(movies$MovieID)
ratings$Timestamp = NULL;
colnames(ratings) = c('user', 'movie', 'rating')
set.seed(100)
train.id = sample(nrow(ratings), floor(nrow(ratings)) * 0.6)
train = ratings[train.id, ]
head(train)
test = ratings[-train.id, ]
test.id = sample(nrow(test), floor(nrow(test)) * 0.5)
test = test[test.id, ]
head(test)
label = test[c('user', 'rating')]
test$rating = NULL
head(label)
head(test)
ratings$Timestamp = NULL;
colnames(ratings) = c('user', 'movie', 'rating')
set.seed(1821)
train.id = sample(nrow(ratings), floor(nrow(ratings)) * 0.6)
train = ratings[train.id, ]
head(train)
test = ratings[-train.id, ]
test.id = sample(nrow(test), floor(nrow(test)) * 0.5)
test = test[test.id, ]
head(test)
label = test[c('user', 'rating')]
test$rating = NULL
head(label)
head(test)
ratings$Timestamp = NULL;
colnames(ratings) = c('user', 'movie', 'rating')
set.seed(1821)
train.id = sample(nrow(ratings), floor(nrow(ratings)) * 0.6)
train = ratings[train.id, ]
head(train)
test = ratings[-train.id, ]
test.id = sample(nrow(test), floor(nrow(test)) * 0.5)
test = test[test.id, ]
head(test)
label = test[c('user', 'rating')]
test$rating = NULL
head(label)
head(test)
View(train)
View(test)
R = acast(train, user ~ movie)
R = as(R, 'realRatingMatrix')
R_m = normalize(R)
head(getRatingMatrix(R_m))
# visualize
image(R, main = "Raw Ratings")
image(R_m, main = "Normalized Ratings")
recommenderRegistry$get_entries(dataType = "realRatingMatrix")
rec = Recommender(R, method = 'UBCF',
parameter = list(normalize = 'Z-score', method = 'Cosine', nn = 5)
)
print(rec)
names(getModel(rec))
recom = predict(rec, R, type = 'ratings')  # predict ratings. This may be slow.
rec_list = as(recom, 'list')  # each element are ratings of that user
test$rating = NA
# For all lines in test file, one by one
for (u in 1:nrow(test)){
# Read userid and movieid from columns 2 and 3 of test data
userid = as.character(test$user[u])
movieid = as.character(test$movie[u])
rating = rec_list[[userid]][movieid]
# 2.5 may be too arbitrary
test$rating[u] = ifelse(is.na(rating), 2.5, rating)
}
View(test)
test$rating
ratings[test.id,]
View(test)
ratings[test.id,]$rating
sqrt(mean((log(test$rating) - log(ratings[test.id,]$rating))^2))
test.id
View(ratings)
(ratings[-train.id, ])[test.id,]
ratings[-train,id][test.id,]
ratings[-train.id,][test.id,]
sqrt(mean((log(test$rating) - log(ratings[train.id,][test.id,]$rating))^2))
sqrt(mean((log(test$rating) - log(ratings[test.id,]$rating))^2))
sqrt(mean((log(test$rating) - log(ratings[train.id,][test.id,]$rating))^2))
ratings[train.id,][test.id,]$rating
ratings[train.id,][test.id,]
sqrt(mean((log(test$rating) - log(ratings[-train.id,][test.id,]$rating))^2))
ratings[-train.id,][test.id,]
sqrt(mean(test$rating - ratings[-train.id,][test.id,]$rating)^2)
sqrt(mean(test$rating - ratings[-train.id,][test.id,]$rating)^2)
rmse(test$rating,ratings[-train.id,][test.id,]$rating)
sqrt(mean(test$rating - ratings[-train.id,][test.id,]$rating)^2)
RMSE(test$rating,ratings[-train.id,][test.id,]$rating)
sqrt(mean((test$rating - ratings[-train.id,][test.id,]$rating)^2))
RMSE(test$rating,ratings[-train.id,][test.id,]$rating)
rec2 = Recommender(R, method = 'IBCF',
parameter = list(normalize = 'Z-score', method = 'Cosine', nn = 5)
)
recom2 = predict(rec2, R, type = 'ratings')  # predict ratings. This may be slow.
rec_list2 = as(recom2, 'list')  # each element are ratings of that user
rec2 = Recommender(R, method = 'IBCF')
recom2 = predict(rec2, R, type = 'ratings')  # predict ratings. This may be slow.
rec_list2 = as(recom2, 'list')  # each element are ratings of that user
test2 = test
test2$rating = NA
# For all lines in test file, one by one
for (u in 1:nrow(test2)){
# Read userid and movieid from columns 2 and 3 of test data
userid = as.character(test2$user[u])
movieid = as.character(test2$movie[u])
rating = rec_list2[[userid]][movieid]
# 2.5 may be too arbitrary
test2$rating[u] = ifelse(is.na(rating), 2.5, rating)
}
RMSE(test$rating,ratings[-train.id,][test.id,]$rating)
RMSE(test2$rating,ratings[-train.id,][test.id,]$rating)
RMSE(test$rating,ratings[-train.id,][test.id,]$rating)
RMSE(test2$rating,ratings[-train.id,][test.id,]$rating)
recommenderRegistry$get_entries(dataType = "realRatingMatrix")
data(BostonHousing)
library(mlbench)
library(MASS)
data(BostonHousing)
data(Boston)
library(MASS)
data(Boston)
data = Boston
head(housing)
data = data(Boston)
data(Boston)
data = Boston
View(data)
View(Boston)
model = lm(medv ~ .)
model = lm(medv ~ .,data)
View(model)
plot(model)
plot(model)
#369,372,373,365
cooks.distance
#369,372,373,365
cooks.distance(model)
n = nrows(data)
n = nrow(data)
#369,372,373,365
cooks.distance(model) > 4/n
#369,372,373,365
data(cooks.distance(model) > 4/n)
#369,372,373,365
data[cooks.distance(model) > 4/n]
#369,372,373,365
data[,c(cooks.distance(model) > 4/n)]
c(cooks.distance(model) > 4/n)
#369,372,373,365
data[c(cooks.distance(model) > 4/n)]
#369,372,373,365
data[c(cooks.distance(model) > 4/n),]
#369,372,373,365
data[cooks.distance(model) > 4/n,]
#369,372,373,365
outliers = data[cooks.distance(model) > 4/n,]
mean(hatvalues(model))
data[hatvalues(model)> 2*mean(hatvalues(model)),]
hatvalues(model)
oultiers = data[hatvalues(model)> 2*mean(hatvalues(model)),]
#369,372,373,365
outliers = data[cooks.distance(model) > 4/n &hatvalues(model)> 2*mean(hatvalues(model)),]
oultiers = data[hatvalues(model)> 0.1,]
oultiers3 = data[-3<rstandard(model)<3,]
oultiers3 = data[rstandard(model)<-3 |rstandard(model)>3,]
oultiers3 = data[rstandard(model)<(-3) |rstandard(model)>3,]
#369,372,373,365
outliers = data[cooks.distance(model) > 4/n &hatvalues(model)> 2*mean(hatvalues(model)) & rstandard(model)<(-3) |rstandard(model)>3,]
data[rstandard(model)<(-3) |rstandard(model)>3,]
oultiers3 = data[rstandard(model)<(-3) ,]
View(oultiers3)
abs(rstandard(model))<(-3)
length(abs(rstandard(model))<(-3))
oultiers3 = data[abs(rstandard(model))<(-3) ,]
oultiers3 = data[abs(rstandard(model))>3 ,]
outliers = data[outlier_resid&outlier_leverage&outlier_cooks,)
outliers = data[outlier_resid&outlier_leverage&outlier_cooks,]
#369,372,373,365
outlier_resid = abs(rstandard(model))>3
outlier_leverage = hatvalues(model)> 0.1
outlier_cooks = cooks.distance(model) > 4/n
outliers = data[outlier_resid&outlier_leverage&outlier_cooks,]
outliers = data[ outlier_leverage & outlier_cooks,]
outlier_leverage = hatvalues(model)> 0.1
data[hatvalues(model)> 0.1,]
2*mean(hatvalues(model))
#369,372,373,365
outlier_resid = abs(rstandard(model))>3
outlier_leverage = hatvalues(model)> 2*mean(hatvalues(model))
outlier_cooks = cooks.distance(model) > 4/n
outliers = data[ outlier_leverage & outlier_cooks,]
outliers = data[ outlier_resid& outlier_leverage & outlier_cooks,]
#369,372,373,365
outlier_resid = abs(rstandard(model))>4
outlier_leverage = hatvalues(model)> 2*mean(hatvalues(model))
outlier_cooks = cooks.distance(model) > 4/n
outliers = data[ outlier_resid& outlier_leverage & outlier_cooks,]
#369,372,373,365
outlier_resid = abs(rstandard(model))>3
data[outlier_resid,]
#369,372,373,365
outlier_resid = abs(rstandard(model))>3
outlier_leverage = hatvalues(model)> 2*mean(hatvalues(model))
outlier_cooks = cooks.distance(model) > 4/n
outliers = data[ outlier_resid& outlier_leverage & outlier_cooks,]
#369,372,373,365
outlier_resid = abs(rstandard(model))>2
outlier_leverage = hatvalues(model)> 2*mean(hatvalues(model))
outlier_cooks = cooks.distance(model) > 4/n
outliers = data[ outlier_resid& outlier_leverage & outlier_cooks,]
data[outlier_resid,]
outlier_leverage & outlier_cooks
data[outlier_leverage,]
number = data[outlier_leverage,]
number = data[outlier_cooks,]
number = data[outlier_resid ,]
outliers = data[ outlier_resid& outlier_leverage & outlier_cooks,]
#369,372,373,365
outlier_resid = abs(rstandard(model))>3
outlier_leverage = hatvalues(model)> 2*mean(hatvalues(model))
outlier_cooks = cooks.distance(model) > 4/n
outliers = data[ outlier_resid& outlier_leverage & outlier_cooks,]
number = data[outlier_resid ,]
#369,372,373,365
outlier_resid = abs(rstandard(model))>2
outlier_leverage = hatvalues(model)> 2*mean(hatvalues(model))
outlier_cooks = cooks.distance(model) > 4/n
outliers = data[ outlier_resid& outlier_leverage & outlier_cooks,]
number = data[outlier_resid ,]
View(outliers)
outliers = data[ outlier_resid | (outlier_leverage & outlier_cooks),]
View(outliers)
#369,372,373,365
outlier_resid = abs(rstandard(model))>3
outlier_leverage = hatvalues(model)> 2*mean(hatvalues(model))
outlier_cooks = cooks.distance(model) > 4/n
outliers = data[ outlier_resid | (outlier_leverage & outlier_cooks),]
number = data[outlier_resid ,]
View(outliers)
#369,372,373,365
outlier_resid = abs(rstandard(model))>3
order(rstandard(model),decreasing = T)
head(data[order(rstandard(model),decreasing = T)],3)
head(data[order(rstandard(model),decreasing = T,)],3)
head(data[order(rstandard(model),decreasing = T),],3)
head(rstandard(model),decreasing = T),3)
head(rstandard(model),decreasing = T,3)
head(order(rstandard(model),decreasing = T),3)
#369,372,373,365
head(order(rstandard(model),decreasing = T),3)
head(order(hatvalues(model),decreasing = T),3)
head(order(cooks.distance(model),decreasing = T),3)
library(MASS)
data(Boston)
data = Boston
n = nrow(data)
model = lm(medv ~ .,data)
plot(model)
cooks_index = head(order(cooks.distance(model),decreasing = T),5)
summary(model)
library(MASS)
data(Boston)
data = Boston
n = nrow(data)
model = lm(medv ~ .,data)
summary(model)
plot(model)
data(Boston)
data = Boston
n = nrow(data)
model = lm(medv ~ .,data)
summary(model)
#2
plot(model)
#2
plot.lm(model)
#2
plot(model,which = c(1:5))
#2
plot(model,which = c(1:5))
#2
plot(model,which = c(1:5))
#369,372,373,365
residual_index = head(order(rstandard(model),decreasing = T),3)
leverage_index = head(order(hatvalues(model),decreasing = T),3)
cooks_index = head(order(cooks.distance(model),decreasing = T),5)
#2
plot(model,which = c(1:5))
#2
plot(model,which = c(1:5))
c(residual_index,leverage_index,cooks_index)
new_data = data(-c(residual_index,leverage_index,cooks_index),)
-c(residual_index,leverage_index,cooks_index)
new_data = data[-c(residual_index,leverage_index,cooks_index),]
new_model = lm(medv ~ .,new_data)
plot(new_model,which = c(1:5))
residual_index = head(order(rstandard(model),decreasing = T),3)
leverage_index = head(order(hatvalues(model),decreasing = T),3)
cooks_index = head(order(cooks.distance(model),decreasing = T),5)
new_data = data[-c(residual_index,leverage_index,cooks_index),]
new_model = lm(medv ~ .,new_data)
plot(new_model,which = c(1:5))
#3
boxcox(new_model)
boxcox(lm(medv~1, data=new_data))
#3
boxcox(new_model)
boxcox(lm(medv~1, data=new_data))
boxcox.lambda(new_model)
BoxCox.lambda(new_model)
#3
out = boxcox(new_model)
View(out)
#3
library(forecast)
install.packages("forecast")
#3
library(forecast)
BoxCox.lambda(new_model)
BoxCox.lambda(new_data$medv)
boxcox(lm(medv~1, data=new_data))
#1
library(MASS)
boxcox(lm(medv~1, data=new_data))
boxcox(new_model)
BoxCox.lambda(new_data$medv)
boxcox(new_model)
boxcox(lm(medv~1, data=new_data))
bc = boxcox(lm(medv~1, data=new_data))
with(bc, x[which.max(y)])
with(bc1, x[which.max(y)])
bc1 = boxcox(new_model)
with(bc1, x[which.max(y)])
BoxCox.lambda(new_data$medv,method=logLik)
BoxCox.lambda(new_data$medv,method='logLik')
BoxCox.lambda(new_data$medv,method='loglik')
#3
bc = boxcox(lm(medv~1, data=new_data))
best_lambda = with(bc, x[which.max(y)])
new_data$medv = (new_data$medv ^ lambda - 1)/lambda
lambda = with(bc, x[which.max(y)])
new_data$medv = (new_data$medv ^ lambda - 1)/lambda
View(new_data)
View(Boston)
View(new_data)
#1
library(MASS)
data(Boston)
data = Boston
n = nrow(data)
model = lm(medv ~ .,data)
summary(model)
plot(model,which = c(1:5))
new_data = data[-c(residual_index,leverage_index,cooks_index),]
new_model = lm(medv ~ .,new_data)
plot(new_model,which = c(1:5))
#3
bc = boxcox(lm(medv~1, data=new_data))
lambda = with(bc, x[which.max(y)])
box_data$medv = (new_data$medv ^ lambda - 1)/lambda
#1
library(MASS)
data(Boston)
data = Boston
n = nrow(data)
model = lm(medv ~ .,data)
summary(model)
plot(model,which = c(1:5))
new_data = data[-c(residual_index,leverage_index,cooks_index),]
new_model = lm(medv ~ .,new_data)
plot(new_model,which = c(1:5))
#3
bc = boxcox(lm(medv~1, data=new_data))
lambda = with(bc, x[which.max(y)])
box_data$medv = (box_data$medv ^ lambda - 1)/lambda
#1
library(MASS)
data(Boston)
data = Boston
n = nrow(data)
model = lm(medv ~ .,data)
summary(model)
plot(model,which = c(1:5))
residual_index = head(order(rstandard(model),decreasing = T),3)
leverage_index = head(order(hatvalues(model),decreasing = T),3)
cooks_index = head(order(cooks.distance(model),decreasing = T),5)
new_data = data[-c(residual_index,leverage_index,cooks_index),]
new_model = lm(medv ~ .,new_data)
bc = boxcox(lm(medv~1, data=new_data))
lambda = with(bc, x[which.max(y)])
box_data$medv = (box_data$medv ^ lambda - 1)/lambda
box_data = new_data
box_data$medv = (box_data$medv ^ lambda - 1)/lambda
box_model = lm(medv ~ .,box_data)
summary(box_model)
box_model = lm(medv ~ 1,box_data)
summary(box_model)
box_model = lm(medv ~ 1,box_data)
summary(box_model)
box_model = lm(medv ~ .,box_data)
summary(box_model)
plot(model,which = c(3))
View(box_data)
plot(box_model,which = c(3))
View(box_model)
box_model$fitted.values
fitted = nthroot(box_model$fitted.values*lambda+1,lambda)
fitted = (box_model$fitted.values*lambda+1)**(-lambda)
fitted = (box_model$fitted.values*lambda+1)^(-lambda)
fitted = (box_model$fitted.values*lambda+1)^(1/lambda)
plot(new_data$medv,fitted)
plot(new_data$medv,fitted,main='Predicted vs True values',
xlab="True house price, ", ylab="Fitted house price")
plot(new_data$medv,fitted,main='Predicted vs True values',
xlab="True house price ", ylab="Fitted house price")
bc = boxcox(lm(medv~1, data=new_data))
lambda = with(bc, x[which.max(y)])
box_data = new_data
#4
box_data$medv = (box_data$medv ^ lambda - 1)/lambda
box_model = lm(medv ~ .,box_data)
plot(box_model,which = c(3))
fitted = (box_model$fitted.values*lambda+1)^(1/lambda)
plot(new_data$medv,fitted,main='Predicted vs True values',
xlab="True house price ", ylab="Fitted house price")
#3
bc = boxcox(lm(medv~1, data=new_data))
lambda = with(bc, x[which.max(y)])
box_data = new_data
#4
box_data$medv = (box_data$medv ^ lambda - 1)/lambda
box_model = lm(medv ~ .,box_data)
plot(box_model,which = c(3))
fitted = (box_model$fitted.values*lambda+1)^(1/lambda)
plot(new_data$medv,fitted,main='Predicted vs True values',
xlab="True house price ", ylab="Fitted house price")
#1
library(MASS)
data(Boston)
data = Boston
n = nrow(data)
model = lm(medv ~ .,data)
summary(model)
plot(model,which = c(1:5))
#2
residual_index = head(abs(order(rstandard(model),decreasing = T)),3)
leverage_index = head(abs(order(hatvalues(model),decreasing = T)),3)
cooks_index = head(order(cooks.distance(model),decreasing = T),5)
new_data = data[-c(residual_index,leverage_index,cooks_index),]
setwd("~/Desktop/illinois/fa18/stat542/stat542_pj4")
library(text2vec)
library(slam)
library(glmnet)
library(pROC)
all = read.table("data.tsv",stringsAsFactors = F,header = T)
